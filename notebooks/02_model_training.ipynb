{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Percorsi locali ai moduli\n",
    "sys.path.append(\"src\")\n",
    "from src.dataset_loader import get_dataloader\n",
    "from src.metrics import compute_metrics\n",
    "\n",
    "# ✅ (Opzionale) attiva logging su wandb\n",
    "try:\n",
    "    import wandb\n",
    "    USE_WANDB = True\n",
    "    wandb.init(project=\"IDC-binary-classification\", name=\"resnet18_run\")\n",
    "except ImportError:\n",
    "    USE_WANDB = False\n",
    "\n",
    "# ⚙️ Configurazioni generali\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"💻 Using device: {device}\")\n",
    "\n",
    "# 📦 Caricamento dataset\n",
    "train_path = \"datasets/dataset_prepared/train\"\n",
    "dataset, _ = get_dataloader(data_dir=train_path, batch_size=32)\n",
    "\n",
    "# 🔁 Usa subset per debug (opzionale)\n",
    "USE_SUBSET = False\n",
    "if USE_SUBSET:\n",
    "    indices = random.sample(range(len(dataset)), int(len(dataset) * 0.1))\n",
    "    dataset = Subset(dataset, indices)\n",
    "\n",
    "# 🔄 Dataloader ottimizzato\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# 🧠 Modello ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# 🔧 Loss e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 📊 Tracciamento metriche\n",
    "history = {k: [] for k in [\"loss\", \"accuracy\", \"precision\", \"recall\", \"f1\"]}\n",
    "best_f1 = 0.0\n",
    "\n",
    "# 🔁 Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # 📊 Metriche epoca\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    history[\"loss\"].append(avg_loss)\n",
    "    for k in metrics:\n",
    "        history[k].append(metrics[k])\n",
    "\n",
    "    print(f\"📈 Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f} | Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1']:.4f}\")\n",
    "\n",
    "    # 💾 Salva best model\n",
    "    if metrics[\"f1\"] > best_f1:\n",
    "        best_f1 = metrics[\"f1\"]\n",
    "        torch.save(model.state_dict(), \"results/best_model.pth\")\n",
    "        print(f\"💾 Best model salvato (F1: {best_f1:.4f})\")\n",
    "\n",
    "    # 🚀 wandb logging\n",
    "    if USE_WANDB:\n",
    "        wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss, **metrics})\n",
    "\n",
    "# 📁 Crea cartella risultati se non esiste\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# 💾 Salva modello finale\n",
    "torch.save(model.state_dict(), \"results/histology_model.pth\")\n",
    "\n",
    "# 💾 Salva storico metriche\n",
    "with open(\"results/train_history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "# 📈 Plot delle metriche\n",
    "plt.figure(figsize=(10, 6))\n",
    "for k in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    plt.plot(history[k], label=k)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"📈 Andamento metriche durante il training\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"results/training_metrics_curve.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Training completato e file salvati in 'results/'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
